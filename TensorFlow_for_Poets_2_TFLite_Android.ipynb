{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# コンバートまで\n",
    "TensorFlow で学習済みのモデルを、`tflite_convert` を使ってコンバートします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/tensorflow-for-poets-2\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "試しに、推論実行\n",
    "\n",
    "\n",
    "推論対象の画像\n",
    "\n",
    "\n",
    "![](tf_files/flower_photos/daisy/3475870145_685a19116d.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluation time (1-image): 0.404s\r\n",
      "\r\n",
      "daisy (score=0.73610)\r\n",
      "dandelion (score=0.24222)\r\n",
      "tulips (score=0.01852)\r\n",
      "roses (score=0.00315)\r\n",
      "sunflowers (score=0.00001)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m scripts.label_image \\\n",
    "  --graph=tf_files/retrained_graph.pb  \\\n",
    "  --image=tf_files/flower_photos/daisy/3475870145_685a19116d.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tflite_convert のヘルプを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tflite_convert [-h] --output_file OUTPUT_FILE\r\n",
      "                      (--graph_def_file GRAPH_DEF_FILE | --saved_model_dir SAVED_MODEL_DIR)\r\n",
      "                      [--output_format {TFLITE,GRAPHVIZ_DOT}]\r\n",
      "                      [--inference_type {FLOAT,QUANTIZED_UINT8}]\r\n",
      "                      [--inference_input_type {FLOAT,QUANTIZED_UINT8}]\r\n",
      "                      [--input_arrays INPUT_ARRAYS]\r\n",
      "                      [--input_shapes INPUT_SHAPES]\r\n",
      "                      [--output_arrays OUTPUT_ARRAYS]\r\n",
      "                      [--saved_model_tag_set SAVED_MODEL_TAG_SET]\r\n",
      "                      [--saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY]\r\n",
      "                      [--std_dev_values STD_DEV_VALUES]\r\n",
      "                      [--mean_values MEAN_VALUES]\r\n",
      "                      [--default_ranges_min DEFAULT_RANGES_MIN]\r\n",
      "                      [--default_ranges_max DEFAULT_RANGES_MAX]\r\n",
      "                      [--drop_control_dependency DROP_CONTROL_DEPENDENCY]\r\n",
      "                      [--reorder_across_fake_quant REORDER_ACROSS_FAKE_QUANT]\r\n",
      "                      [--change_concat_input_ranges CHANGE_CONCAT_INPUT_RANGES]\r\n",
      "                      [--allow_custom_ops ALLOW_CUSTOM_OPS]\r\n",
      "\r\n",
      "Command line tool to run TensorFlow Lite Optimizing Converter (TOCO).\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  --output_file OUTPUT_FILE\r\n",
      "                        Full filepath of the output file.\r\n",
      "  --graph_def_file GRAPH_DEF_FILE\r\n",
      "                        Full filepath of file containing TensorFlow GraphDef.\r\n",
      "  --saved_model_dir SAVED_MODEL_DIR\r\n",
      "                        Full filepath of directory containing the SavedModel.\r\n",
      "  --output_format {TFLITE,GRAPHVIZ_DOT}\r\n",
      "                        Output file format.\r\n",
      "  --inference_type {FLOAT,QUANTIZED_UINT8}\r\n",
      "                        Target data type of arrays in the output file.\r\n",
      "  --inference_input_type {FLOAT,QUANTIZED_UINT8}\r\n",
      "                        Target data type of input arrays. Allows for a\r\n",
      "                        different type for input arrays in the case of\r\n",
      "                        quantization.\r\n",
      "  --input_arrays INPUT_ARRAYS\r\n",
      "                        Names of the output arrays, comma-separated.\r\n",
      "  --input_shapes INPUT_SHAPES\r\n",
      "                        Shapes corresponding to --input_arrays, colon-\r\n",
      "                        separated.\r\n",
      "  --output_arrays OUTPUT_ARRAYS\r\n",
      "                        Names of the output arrays, comma-separated.\r\n",
      "  --saved_model_tag_set SAVED_MODEL_TAG_SET\r\n",
      "                        Comma-separated set of tags identifying the\r\n",
      "                        MetaGraphDef within the SavedModel to analyze. All\r\n",
      "                        tags must be present. (default \"serve\")\r\n",
      "  --saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY\r\n",
      "                        Key identifying the SignatureDef containing inputs and\r\n",
      "                        outputs. (default DEFAULT_SERVING_SIGNATURE_DEF_KEY)\r\n",
      "  --std_dev_values STD_DEV_VALUES\r\n",
      "                        Standard deviation of training data for each input\r\n",
      "                        tensor, comma-separated. Used for quantization.\r\n",
      "                        (default None)\r\n",
      "  --mean_values MEAN_VALUES\r\n",
      "                        Mean of training data for each input tensor, comma-\r\n",
      "                        separated. Used for quantization. (default None)\r\n",
      "  --default_ranges_min DEFAULT_RANGES_MIN\r\n",
      "                        Default value for min bound of min/max range values\r\n",
      "                        used for all arrays without a specified range,\r\n",
      "                        Intended for experimenting with quantization via\r\n",
      "                        \"dummy quantization\". (default None)\r\n",
      "  --default_ranges_max DEFAULT_RANGES_MAX\r\n",
      "                        Default value for max bound of min/max range values\r\n",
      "                        used for all arrays without a specified range,\r\n",
      "                        Intended for experimenting with quantization via\r\n",
      "                        \"dummy quantization\". (default None)\r\n",
      "  --drop_control_dependency DROP_CONTROL_DEPENDENCY\r\n",
      "                        Boolean indicating whether to drop control\r\n",
      "                        dependencies silently. This is due to TensorFlow not\r\n",
      "                        supporting control dependencies. (default True)\r\n",
      "  --reorder_across_fake_quant REORDER_ACROSS_FAKE_QUANT\r\n",
      "                        Boolean indicating whether to reorder FakeQuant nodes\r\n",
      "                        in unexpected locations. Used when the location of the\r\n",
      "                        FakeQuant nodes is preventing graph transformations\r\n",
      "                        necessary to convert the graph. Results in a graph\r\n",
      "                        that differs from the quantized training graph,\r\n",
      "                        potentially causing differing arithmetic behavior.\r\n",
      "                        (default False)\r\n",
      "  --change_concat_input_ranges CHANGE_CONCAT_INPUT_RANGES\r\n",
      "                        Boolean to change behavior of min/max ranges for\r\n",
      "                        inputs and outputs of the concat operator for\r\n",
      "                        quantized models. Changes the ranges of concat\r\n",
      "                        operator overlap when true. (default False)\r\n",
      "  --allow_custom_ops ALLOW_CUSTOM_OPS\r\n",
      "                        Boolean indicating whether to allow custom operations.\r\n",
      "                        When false any unknown operation is an error. When\r\n",
      "                        true, custom ops are created for any op that is\r\n",
      "                        unknown. The developer will need to provide these to\r\n",
      "                        the TensorFlow Lite runtime with a custom resolver.\r\n",
      "                        (default False)\r\n"
     ]
    }
   ],
   "source": [
    "!tflite_convert --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コンバートを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: tflite_convert [-h] --output_file OUTPUT_FILE\r\n",
      "                      (--graph_def_file GRAPH_DEF_FILE | --saved_model_dir SAVED_MODEL_DIR)\r\n",
      "                      [--output_format {TFLITE,GRAPHVIZ_DOT}]\r\n",
      "                      [--inference_type {FLOAT,QUANTIZED_UINT8}]\r\n",
      "                      [--inference_input_type {FLOAT,QUANTIZED_UINT8}]\r\n",
      "                      [--input_arrays INPUT_ARRAYS]\r\n",
      "                      [--input_shapes INPUT_SHAPES]\r\n",
      "                      [--output_arrays OUTPUT_ARRAYS]\r\n",
      "                      [--saved_model_tag_set SAVED_MODEL_TAG_SET]\r\n",
      "                      [--saved_model_signature_key SAVED_MODEL_SIGNATURE_KEY]\r\n",
      "                      [--std_dev_values STD_DEV_VALUES]\r\n",
      "                      [--mean_values MEAN_VALUES]\r\n",
      "                      [--default_ranges_min DEFAULT_RANGES_MIN]\r\n",
      "                      [--default_ranges_max DEFAULT_RANGES_MAX]\r\n",
      "                      [--drop_control_dependency DROP_CONTROL_DEPENDENCY]\r\n",
      "                      [--reorder_across_fake_quant REORDER_ACROSS_FAKE_QUANT]\r\n",
      "                      [--change_concat_input_ranges CHANGE_CONCAT_INPUT_RANGES]\r\n",
      "                      [--allow_custom_ops ALLOW_CUSTOM_OPS]\r\n",
      "tflite_convert: error: \r\n"
     ]
    }
   ],
   "source": [
    "# エラーになります\n",
    "!IMAGE_SIZE=224\n",
    "!tflite_convert \\\n",
    "  --graph_def_file=tf_files/retrained_graph.pb \\\n",
    "  --output_file=tf_files/optimized_graph.lite \\\n",
    "  --input_format=TENSORFLOW_GRAPHDEF \\\n",
    "  --output_format=TFLITE \\\n",
    "  --input_shape=1,${IMAGE_SIZE},${IMAGE_SIZE},3 \\\n",
    "  --input_array=input \\\n",
    "  --output_array=final_result \\\n",
    "  --inference_type=FLOAT \\\n",
    "  --input_data_type=FLOAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flower_photos  retrained_graph.pb  retrained_labels.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./tf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tflite_convert \\\n",
    "  --graph_def_file=./tf_files/retrained_graph.pb \\\n",
    "  --output_file=./tf_files/optimized_graph.lite \\\n",
    "  --output_format=TFLITE \\\n",
    "  --input_shapes=1,224,224,3 \\\n",
    "  --input_arrays=input \\\n",
    "  --output_arrays=final_result \\\n",
    "  --inference_type=FLOAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flower_photos  optimized_graph.lite  retrained_graph.pb  retrained_labels.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./tf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出力された、 `./tf_files/optimized_graph.lite` を利用します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
